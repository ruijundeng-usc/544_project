{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "544Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNauMRFfzlJy"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zCe663F2Ltj"
      },
      "source": [
        "#Prepare inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvgqtyb5zPlx"
      },
      "source": [
        "## Need to do\n",
        "## Prepare data using RAKE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7AlFQ5f2ubs"
      },
      "source": [
        "df = pd.read_csv(\"ROCStories_winter2017 - ROCStories_winter2017.csv\")\n",
        "# Need to prepare data format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSbre6o1zHB8"
      },
      "source": [
        "## Using Provided Data for testing \n",
        "in https://github.com/rishishian/plan_write/tree/master/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4bs_8fezeX1"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# split src data to (title+line) and (line+story)\n",
        "src_data_path_list = ['train_title_line_story.txt', 'valid_title_line_story.txt', 'test_title_line_story.txt']\n",
        "t2l_data_path_list = ['train_title_line.tsv', 'valid_title_line.tsv', 'test_title_line.tsv']\n",
        "l2s_data_path_list = ['train_line_story.tsv', 'valid_line_story.tsv', 'test_line_story.tsv']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUWJvH7lbqfC",
        "outputId": "58aa137f-38d6-4342-80f9-92f6734438b1"
      },
      "source": [
        "\n",
        "def parse_line(line):\n",
        "    title, rest = line.split('<EOT>')\n",
        "    story_line, story = rest.split('<EOL>')\n",
        "    return title.strip(), story_line.strip(), story.strip()\n",
        "\n",
        "\n",
        "for src_data_path, t2l_data_path, l2s_data_path in zip(src_data_path_list, t2l_data_path_list, l2s_data_path_list):\n",
        "    with open(src_data_path, 'r') as src_file:\n",
        "        with open(t2l_data_path, 'w') as t2l_file:\n",
        "            with open(l2s_data_path, 'w') as l2s_file:\n",
        "                print(f'Processing {src_data_path}')\n",
        "                src_lines = src_file.readlines()\n",
        "                for line in tqdm(src_lines):\n",
        "                    title, story_line, story = parse_line(line)\n",
        "                    t2l_file.write(title + '\\t' + story_line + '\\n')\n",
        "                    l2s_file.write(story_line + '\\t' + story + '\\n')\n",
        "\n",
        "# ground-truth story for testset\n",
        "gt_testset_path = 'test_story.txt'\n",
        "with open(src_data_path_list[-1], 'r') as src_file:\n",
        "    with open(gt_testset_path, 'w') as gt_file:\n",
        "        src_lines = src_file.readlines()\n",
        "        for line in tqdm(src_lines):\n",
        "            title, story_line, story = parse_line(line)\n",
        "            gt_file.write(story + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing train_title_line_story.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80186/80186 [00:00<00:00, 351126.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing valid_title_line_story.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9816/9816 [00:00<00:00, 301990.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test_title_line_story.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8159/8159 [00:00<00:00, 333135.33it/s]\n",
            "100%|██████████| 8159/8159 [00:00<00:00, 268398.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4drFd6q6cJVi"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "from torchtext.legacy.data import Field, TabularDataset\n",
        "\n",
        "\n",
        "class TitleLine(TabularDataset):\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.story_line)\n",
        "\n",
        "\n",
        "class LineStory(TabularDataset):\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.story_line)\n",
        "\n",
        "\n",
        "VOCAB = Field(init_token='<sos>', eos_token='<eos>', lower=True)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_mELgqs0csN"
      },
      "source": [
        "# Define all models used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Z6v4pj_cD9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, n_layer=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional=True, num_layers=n_layer)\n",
        "        #nn.LSTM(self.embedding_size, self.hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        \n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
        "\n",
        "        return outputs, hidden\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaLaYG1Hz6kh"
      },
      "source": [
        "\n",
        "class SelfAttention(torch.nn.Module):\n",
        "    def __init__(self, qkv_dimensions, hidden_size=256, n_heads=4, output_dim=None, dropout=0.1, normaliza_qk=False):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_heads = n_heads\n",
        "        if self.hidden_size % self.n_heads != 0:\n",
        "            raise ValueError(\"Hidden size must be evenly divisible by the number of heads.\")\n",
        "        self.dropout = dropout\n",
        "        self.dropout = nn.Dropout(dropout) if 0 < dropout < 1 else None\n",
        "        self.normalize_qk = normaliza_qk\n",
        "\n",
        "        q_dim, k_dim, v_dim = qkv_dimensions\n",
        "        self.q_proj = nn.Linear(q_dim, self.hidden_size, bias=False)\n",
        "        self.k_proj = nn.Linear(k_dim, self.hidden_size, bias=False)\n",
        "        self.v_proj = nn.Linear(v_dim, self.hidden_size, bias=False)\n",
        "\n",
        "        if output_dim is None:\n",
        "            self.output_transform = None\n",
        "        else:\n",
        "            self.output_transform = nn.Linear(self.hidden_size, output_dim, bias=False)\n",
        "\n",
        "    @property\n",
        "    def depth(self):\n",
        "        return self.hidden_size // self.n_heads\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        k_equal_q = k is None\n",
        "        if self.q_proj is not None:\n",
        "            q = self.q_proj(q)\n",
        "        if k_equal_q:\n",
        "            k = q\n",
        "        elif self.k_proj is not None:\n",
        "            k = self.k_proj(k)\n",
        "        if self.v_proj is not None:\n",
        "            v = self.v_proj(v)\n",
        "        if self.n_heads > 1:\n",
        "            q = self._split_heads(q)\n",
        "            if not k_equal_q:\n",
        "                k = self._split_heads(k)\n",
        "            v = self._split_heads(v)\n",
        "        if self.normalize_qk:\n",
        "            q = q / torch.norm(q, dim=-1).unsqueeze(-1)\n",
        "            if not k_equal_q:\n",
        "                k = k / torch.norm(k, dim=-1).unsqueeze(-1)\n",
        "        if k_equal_q:\n",
        "            k = q\n",
        "        q = q * self.depth ** -0.5\n",
        "\n",
        "        # q, k, v  : [num_heads x B, T, depth]\n",
        "        logits = torch.bmm(q, k.transpose(1, 2))\n",
        "        weights = F.softmax(logits, dim=-1)\n",
        "        if self.dropout is not None:\n",
        "            weights = self.dropout(weights)\n",
        "        attention_output = torch.bmm(weights, v)\n",
        "        attention_output = self._combine_heads(attention_output)\n",
        "        if self.output_transform is not None:\n",
        "            attention_output = self.output_transform(attention_output)\n",
        "        return attention_output\n",
        "\n",
        "    def _split_heads(self, x):\n",
        "        time_step = x.shape[1]\n",
        "        return (\n",
        "            x.view(-1, time_step, self.n_heads, self.depth)\n",
        "                .transpose(1, 2).contiguous()\n",
        "                .view(-1, time_step, self.depth)\n",
        "        )\n",
        "\n",
        "    def _combine_heads(self, x):\n",
        "        time_step = x.shape[1]\n",
        "        return (\n",
        "            x.view(-1, self.n_heads, time_step, self.depth)\n",
        "                .transpose(1, 2).contiguous()\n",
        "                .view(-1, time_step, self.hidden_size)\n",
        "        )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRZ6wmH0BOX"
      },
      "source": [
        "\n",
        "class Encoder_with_SelfAttn(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, n_layer=2):\n",
        "        assert n_layer > 1\n",
        "        print('Enter Encoder with Self Attention')\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional=True, num_layers=n_layer)\n",
        "\n",
        "        qkv_dimensions = [enc_hid_dim, enc_hid_dim, enc_hid_dim + emb_dim]\n",
        "        self.self_attentions = torch.nn.ModuleList([\n",
        "            SelfAttention(qkv_dimensions, enc_hid_dim, n_heads=4)\n",
        "            for _ in range(n_layer - 1)\n",
        "        ])\n",
        "\n",
        "        input_dimensions = [emb_dim] + [enc_hid_dim] * (n_layer - 1)\n",
        "        self.rnns = torch.nn.ModuleList([nn.GRU(\n",
        "            dim, enc_hid_dim, 1,\n",
        "            batch_first=True, bidirectional=True  # batch first 的问题需要改一下\n",
        "        ) for dim in input_dimensions])\n",
        "\n",
        "        self.bidirectional_projections = torch.nn.ModuleList(\n",
        "            [nn.Linear(enc_hid_dim * 2, enc_hid_dim, bias=False)\n",
        "             for _ in range(n_layer)])\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src sent len, batch size]\n",
        "        src = src.transpose(0, 1)\n",
        "\n",
        "        embedded = self.embedding_dropout(self.embedding(src))\n",
        "\n",
        "        # embedded = [src sent len, batch size, emb dim]\n",
        "\n",
        "        net = embedded\n",
        "        for i, rnn in enumerate(self.rnns):\n",
        "            net, final_state = rnn(net, None)\n",
        "            if self.bidirectional_projections is not None and i < len(self.rnns) - 1:\n",
        "                net = self.bidirectional_projections[i](net)\n",
        "            if self.self_attentions is not None and i < len(self.rnns) - 1:\n",
        "                net = self.self_attentions[i](net, net, torch.cat([embedded, net], dim=2))\n",
        "        # net = [bs, len, hid_dim * 2]\n",
        "        outputs = net.transpose(0, 1)\n",
        "\n",
        "        # outputs = [src sent len, batch size, hid dim * num directions]\n",
        "\n",
        "        # initial decoder hidden is final hidden state of the forwards and backwards\n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(net[:, -1, :]))\n",
        "\n",
        "        # outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        # hidden = [batch size, dec hid dim]\n",
        "        return outputs, hidden\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvITHE-D0ExQ"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        assert (output == hidden).all()\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output, weighted, embedded), dim=1))\n",
        "\n",
        "        return output, hidden.squeeze(0)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF-iGKe00SIh"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # repeat encoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "\n",
        "        energy = energy.permute(0, 2, 1)\n",
        "\n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "\n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXbS92t00VG4"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    MAX_DECODE_LEN = 100\n",
        "\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg=None, teacher_forcing_ratio=1.0):\n",
        "        batch_size = src.shape[1]\n",
        "        if trg is not None:\n",
        "            max_len = trg.shape[0]\n",
        "        else:\n",
        "            assert teacher_forcing_ratio == 0\n",
        "            max_len = Seq2Seq.MAX_DECODE_LEN\n",
        "\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = src[0, :]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            # insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            # receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-u7k1HqA0Bf"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, src_field, trg_field, iterator, optimizer, criterion, clip, teacher_force):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = getattr(batch, src_field)\n",
        "        trg = getattr(batch, trg_field)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, teacher_force)\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, src_field, trg_field, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = getattr(batch, src_field)\n",
        "            trg = getattr(batch, trg_field)\n",
        "            output = model(src, trg, 0)  # no teacher forcing\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def decode_story(output, vocab, join=' '):\n",
        "    id_tensor = output.argmax(2)\n",
        "    ids = id_tensor.transpose(0, 1)\n",
        "    sent_batch = []\n",
        "    for i in range(ids.shape[0]):\n",
        "        sent = []\n",
        "        for j in range(ids.shape[1]):\n",
        "            w = vocab.itos[ids[i][j]]\n",
        "            sent.append(w)\n",
        "        sent = join.join(sent)\n",
        "        sent_batch.append(sent)\n",
        "    return sent_batch\n",
        "\n",
        "\n",
        "def decode_story_line(output, vocab, join=' '):\n",
        "    output = output.squeeze(1)\n",
        "    sent = []\n",
        "    values, indices = torch.topk(output, k=7, dim=1)\n",
        "    decoded_indices = []\n",
        "    # forbid any word to appear twice in storyline\n",
        "    for i in range(output.shape[0]):  # for the i-th word\n",
        "        for idx in indices[i]:  # for top-k candidate\n",
        "            if idx not in decoded_indices:\n",
        "                # a new word\n",
        "                w = vocab.itos[idx]\n",
        "                decoded_indices.append(idx)\n",
        "                if w == '<unk>':  #\n",
        "                    continue\n",
        "                sent.append(w)\n",
        "                break\n",
        "    sent = join.join(sent)\n",
        "    return [sent]\n",
        "\n",
        "\n",
        "def test_generate(model, src_field, trg_field, iterator, criterion, result_path, decode_func, compute_loss):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    generated_sentence = []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in tqdm(enumerate(iterator)):\n",
        "            src = getattr(batch, src_field)\n",
        "            trg = getattr(batch, trg_field) if compute_loss else None\n",
        "            output = model(src, trg, 0) \n",
        "            generated_sentence.extend(decode_func(output, VOCAB.vocab, join=' '))\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            if compute_loss:\n",
        "                trg = trg[1:].view(-1)\n",
        "                loss = criterion(output, trg)\n",
        "                epoch_loss += loss.item()\n",
        "    test_loss = epoch_loss / len(iterator) if epoch_loss else 'Test Loss Not Computed.'\n",
        "    with open(result_path, 'w') as f:\n",
        "        for sent in generated_sentence:\n",
        "            f.write(sent + '\\n')\n",
        "    return test_loss, generated_sentence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S73S4Eyim_ZE",
        "outputId": "12269b44-d0f0-491c-a649-3e6695452ca5"
      },
      "source": [
        "trainset_path = 'train_title_line.tsv'\n",
        "validset_path = 'valid_title_line.tsv'\n",
        "testset_path = 'test_title_line.tsv'\n",
        "print(f'train/valid/test dataset path:{trainset_path}/{validset_path}/{testset_path}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/valid/test dataset path:train_title_line.tsv/valid_title_line.tsv/test_title_line.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW16rrDInXMi",
        "outputId": "ddb8b844-780a-47ee-e668-93dd6393f091"
      },
      "source": [
        "src_field, trg_field = 'title', 'story_line'\n",
        "named_fields = [(src_field, VOCAB), (trg_field, VOCAB)]\n",
        "print(f'src_filed:{src_field}, trg_field:{trg_field}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_filed:title, trg_field:story_line\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOCzaFEEoK0t"
      },
      "source": [
        "class TitleLine(TabularDataset):\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.story_line)\n",
        "\n",
        "\n",
        "class LineStory(TabularDataset):\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.story_line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxWrvM6IoQTO"
      },
      "source": [
        "DataSet = TitleLine if trg_field == 'story_line' else LineStory\n",
        "train_data = DataSet(path=trainset_path, format='tsv', fields=named_fields)\n",
        "valid_data = DataSet(path=validset_path, format='tsv', fields=named_fields)\n",
        "test_data = DataSet(path=testset_path, format='tsv', fields=named_fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1_LO0KgoTgG",
        "outputId": "d3b57b73-8d49-4d00-b93d-87661db72ee9"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
        "print('Show data example')\n",
        "print(vars(train_data.examples[0]), vars(valid_data.examples[0]), vars(test_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 80186\n",
            "Number of validation examples: 9816\n",
            "Number of testing examples: 8159\n",
            "Show data example\n",
            "{'title': ['overweight', 'kid'], 'story_line': ['dan', 'overweight', 'unhealthy', 'make', 'decided']} {'title': ['the', 'pet', 'bug'], 'story_line': ['oliver', 'spotted', 'jar', 'hoped', 'safe']} {'title': ['literature', 'vs', 'math'], 'story_line': ['literature', 'choose', 'indecisive', 'make', 'deny']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pePU9PqNobXp",
        "outputId": "666229a6-34d8-4b63-b46b-df2b5490fbbd"
      },
      "source": [
        "VOCAB.build_vocab(train_data, min_freq=25)\n",
        "print(f\"Unique tokens in vocabulary(min frequency:{25}): {len(VOCAB.vocab)}\")\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in vocabulary(min frequency:25): 3372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGmhR-fZzhpH",
        "outputId": "076da7d3-5a6d-4a8e-e4ee-55bf955741b4"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSG9wagyovG7"
      },
      "source": [
        "from torchtext.legacy.data import Iterator, BucketIterator\n",
        "train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data),\n",
        "                                                           batch_size=128, device=device)\n",
        "test_iterator = Iterator(test_data, batch_size=1, device=device, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbtRaRTM1i87"
      },
      "source": [
        "# Title to Storyline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bm1k7NYpK5Z",
        "outputId": "d4e9cade-aa00-46ef-90b0-950867ac5ee4"
      },
      "source": [
        "# model\n",
        "INPUT_DIM = len(VOCAB.vocab)\n",
        "OUTPUT_DIM = len(VOCAB.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 256\n",
        "DEC_HID_DIM = 256\n",
        "N_LAYERS = 1\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "# enc = Encoder_with_SelfAttn(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device:{device}')\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "print(f'The model has {count_parameters(model)} trainable parameters')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "PAD_IDX = VOCAB.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "N_EPOCHS = 5\n",
        "CLIP = 1\n",
        "TEACHER_FORCE = 0.5\n",
        "MODEL_PATH = 'title2line.pt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:cuda\n",
            "The model has 7614508 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uDy1J-hv3x",
        "outputId": "25a90938-9e30-45a5-b5fe-9d0ea6be5955"
      },
      "source": [
        "print(f'Training {src_field} to {trg_field} model')\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, src_field, trg_field, train_iterator, optimizer, criterion, CLIP, TEACHER_FORCE)\n",
        "    valid_loss = evaluate(model, src_field, trg_field, valid_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training story_line to story model \n",
            " Epoch: 01 | Time: 11m 57s \n",
            " Train Loss: 4.807 | Train PPL: 122.375 \n",
            " Val. Loss: 5.520 |  Val. PPL: 249.582 \n",
            " Epoch: 02 | Time: 11m 57s \n",
            " Train Loss: 4.163 | Train PPL:  64.270 \n",
            " Val. Loss: 5.427 |  Val. PPL: 227.458 \n",
            " Epoch: 03 | Time: 11m 58s \n",
            " Train Loss: 3.928 | Train PPL:  50.791 \n",
            " Val. Loss: 5.516 |  Val. PPL: 248.587 \n",
            " Epoch: 04 | Time: 11m 58s \n",
            "  Train Loss: 3.793 | Train PPL:  44.407 \n",
            " Val. Loss: 5.459 |  Val. PPL: 234.898 \n",
            " Epoch: 05 | Time: 11m 58s \n",
            " Train Loss: 3.688 | Train PPL:  39.977 \n",
            " Val. Loss: 5.460 |  Val. PPL: 235.056 \n",
            " 8159it [15:41,  8.66it/s]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCOHcZSU7Xk_"
      },
      "source": [
        "def test_bleu(result_path):\n",
        "    GT_PATH = 'test_story.txt'\n",
        "    with open(GT_PATH, encoding=\"utf-8\") as f:\n",
        "        refs = f.readlines()\n",
        "        refs = [''.join(l.split('</s>')) for l in refs]\n",
        "\n",
        "    with open(result_path, encoding='utf-8') as f:\n",
        "        raw_sents = f.readlines()\n",
        "        cans = []\n",
        "        for l in raw_sents:\n",
        "            for sep in ['</s>', '<unk>', '<eos>']:\n",
        "                l = l.replace(sep, '')\n",
        "            cans.append(l.strip())\n",
        "\n",
        "    assert len(cans) == len(refs), print(len(cans), len(refs))\n",
        "    score_list = []\n",
        "    for ref, can in zip(refs, cans):\n",
        "        score_list.append(bleu_score(ref, can))\n",
        "    sentence_bleu = np.mean(score_list)\n",
        "    print(f'Sentence bleu score:{sentence_bleu}')\n",
        "\n",
        "\n",
        "def create_testfile(generated_line_path='title2line.txt'):\n",
        "    base, ext = os.path.splitext(generated_line_path)\n",
        "    ext = '_fortest.tsv'\n",
        "    dest_file = base + ext\n",
        "    print(f'Refining Test File(from:{generated_line_path}, to:{dest_file})')\n",
        "    with open(generated_line_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = [l.strip() + '\\t' + f'STORY {i} TO BE GENERATED\\n' for i, l in enumerate(lines)]\n",
        "        with open(dest_file, 'w') as wf:\n",
        "            for line in new_lines:\n",
        "                wf.write(line)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O7Pdb4k7MpC"
      },
      "source": [
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "RESULT_PATH = 'title2line.txt'\n",
        "decode_func = decode_story_line if trg_field == 'story_line' else decode_story\n",
        "compute_loss = True if trg_field == 'story_line' else False\n",
        "test_loss, result = test_generate(model, src_field, trg_field, test_iterator, criterion, RESULT_PATH,\n",
        "                                  decode_func, compute_loss)\n",
        "if trg_field == 'story_line':\n",
        "    print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss)} |')\n",
        "    create_testfile(RESULT_PATH)\n",
        "elif trg_field == 'story':\n",
        "    test_bleu(RESULT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfXjaViK1p8y"
      },
      "source": [
        "# Storyline to Story"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VN8SVTc-C5x"
      },
      "source": [
        "trainset_path = 'train_line_story.tsv'\n",
        "validset_path = 'valid_line_story.tsv'\n",
        "testset_path = 'test_line_story.tsv'\n",
        "print(f'train/valid/test dataset path:{trainset_path}/{validset_path}/{testset_path}')\n",
        "src_field, trg_field = 'story_line', 'story'\n",
        "named_fields = [(src_field, VOCAB), (trg_field, VOCAB)]\n",
        "print(f'src_filed:{src_field}, trg_field:{trg_field}')\n",
        "DataSet = TitleLine if trg_field == 'story_line' else LineStory\n",
        "train_data = DataSet(path=trainset_path, format='tsv', fields=named_fields)\n",
        "valid_data = DataSet(path=validset_path, format='tsv', fields=named_fields)\n",
        "test_data = DataSet(path=testset_path, format='tsv', fields=named_fields)\n",
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
        "print('Show data example')\n",
        "print(vars(train_data.examples[0]), vars(valid_data.examples[0]), vars(test_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyu5O5tJAv4v"
      },
      "source": [
        "VOCAB.build_vocab(train_data, min_freq=25)\n",
        "print(f\"Unique tokens in vocabulary(min frequency:{25}): {len(VOCAB.vocab)}\")\n",
        "train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data),\n",
        "                                                           batch_size=128, device=device)\n",
        "test_iterator = Iterator(test_data, batch_size=1, device=device, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAnM33hjBAsB"
      },
      "source": [
        "# model\n",
        "INPUT_DIM = len(VOCAB.vocab)\n",
        "OUTPUT_DIM = len(VOCAB.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 256\n",
        "DEC_HID_DIM = 256\n",
        "N_LAYERS = 1\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "# enc = Encoder_with_SelfAttn(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device:{device}')\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "print(f'The model has {count_parameters(model)} trainable parameters')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "PAD_IDX = VOCAB.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "N_EPOCHS = 5\n",
        "CLIP = 1\n",
        "TEACHER_FORCE = 0.5\n",
        "MODEL_PATH = 'line2story.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTjnmzsCSO0"
      },
      "source": [
        "print(f'Training {src_field} to {trg_field} model')\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, src_field, trg_field, train_iterator, optimizer, criterion, CLIP, TEACHER_FORCE)\n",
        "    valid_loss = evaluate(model, src_field, trg_field, valid_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7RjdGdbWdSq3",
        "outputId": "2e0000be-e5e2-4eba-8d56-05a45bae1d30"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('544Project.ipynb')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘colab_pdf.py’ already there; not retrieving.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/544Project.ipynb to pdf\n",
            "[NbConvertApp] Writing 147401 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: [u'xelatex', u'./notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: [u'bibtex', u'./notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 105884 bytes to /content/drive/My Drive/544Project.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_28050fbd-c8c6-4f1e-8582-07fa0944fc00\", \"544Project.pdf\", 105884)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File ready to be Downloaded and Saved to Drive'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHVz3ttW1zV8"
      },
      "source": [
        "# DNU: Do Not Use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tILoqkI_1Tta"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x, dropout=0.5):\n",
        "        if not self.training or not dropout:\n",
        "            return x\n",
        "        m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n",
        "        mask = Variable(m, requires_grad=False) / (1 - dropout)\n",
        "        mask = mask.expand_as(x)\n",
        "        return mask * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQJUKPT02EU"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from embed_regularize import embedded_dropout\n",
        "from locked_dropout import LockedDropout\n",
        "from weight_drop import WeightDrop\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, dropouth=0.5, dropouti=0.5, dropoute=0.1, wdrop=0, tie_weights=False):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.lockdrop = LockedDropout()\n",
        "        self.idrop = nn.Dropout(dropouti)\n",
        "        self.hdrop = nn.Dropout(dropouth)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        assert rnn_type in ['LSTM', 'QRNN', 'GRU'], 'RNN type is not supported'\n",
        "        self.rnns = [torch.nn.LSTM(ninp if l == 0 else nhid, nhid if l != nlayers - 1 else (ninp if tie_weights else nhid), 1, dropout=0) for l in range(nlayers)]\n",
        "        if wdrop:\n",
        "          self.rnns = [WeightDrop(rnn, ['weight_hh_l0'], dropout=wdrop) for rnn in self.rnns]\n",
        "        print(self.rnns)\n",
        "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "        if tie_weights:\n",
        "           self.decoder.weight = self.encoder.weight\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.ninp = ninp\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "        self.dropout = dropout\n",
        "        self.dropouti = dropouti\n",
        "        self.dropouth = dropouth\n",
        "        self.dropoute = dropoute\n",
        "        self.tie_weights = tie_weights\n",
        "\n",
        "    def reset(self):\n",
        "        if self.rnn_type == 'QRNN': [r.reset() for r in self.rnns]\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.fill_(0)\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden, return_h=False):\n",
        "        emb = embedded_dropout(self.encoder, input, dropout=self.dropoute if self.training else 0)\n",
        "        #emb = self.idrop(emb)\n",
        "\n",
        "        emb = self.lockdrop(emb, self.dropouti)\n",
        "\n",
        "        raw_output = emb\n",
        "        new_hidden = []\n",
        "        #raw_output, hidden = self.rnn(emb, hidden)\n",
        "        raw_outputs = []\n",
        "        outputs = []\n",
        "        for l, rnn in enumerate(self.rnns):\n",
        "            current_input = raw_output\n",
        "            raw_output, new_h = rnn(raw_output, hidden[l])\n",
        "            new_hidden.append(new_h)\n",
        "            raw_outputs.append(raw_output)\n",
        "            if l != self.nlayers - 1:\n",
        "                #self.hdrop(raw_output)\n",
        "                raw_output = self.lockdrop(raw_output, self.dropouth)\n",
        "                outputs.append(raw_output)\n",
        "        hidden = new_hidden\n",
        "\n",
        "        output = self.lockdrop(raw_output, self.dropout)\n",
        "        outputs.append(output)\n",
        "\n",
        "        result = output.view(output.size(0)*output.size(1), output.size(2))\n",
        "        #print(result.shape)\n",
        "        if return_h:\n",
        "            return result, hidden, raw_outputs, outputs\n",
        "        return result, hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters()).data\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return [(weight.new(1, bsz, self.nhid if l != self.nlayers - 1 else (self.ninp if self.tie_weights else self.nhid)).zero_(),\n",
        "                    weight.new(1, bsz, self.nhid if l != self.nlayers - 1 else (self.ninp if self.tie_weights else self.nhid)).zero_())\n",
        "                    for l in range(self.nlayers)]\n",
        "        elif self.rnn_type == 'QRNN' or self.rnn_type == 'GRU':\n",
        "            return [weight.new(1, bsz, self.nhid if l != self.nlayers - 1 else (self.ninp if self.tie_weights else self.nhid)).zero_()\n",
        "                    for l in range(self.nlayers)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hc9SAUc1Um9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "class PoolEndingClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
        "                 embed_mat=None, fix_embeddings=False):\n",
        "        super(PoolEndingClassifier, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if embed_mat is not None:\n",
        "            self.word_embeds.weight.data = embed_mat\n",
        "            if fix_embeddings:\n",
        "                self.word_embeds.weight.requires_grad=False\n",
        "        \n",
        "        self.fc = nn.Linear(self.embedding_dim, 1)\n",
        "\n",
        "    def embed_seq(self, vec):\n",
        "        vec1 = self.word_embeds(vec.transpose(0, 1).contiguous())\n",
        "        vec_tr = vec1.transpose(1, 2).contiguous()\t\n",
        "        return vec_tr # dim [batch_size, embed_dim, length]\n",
        "\n",
        "    # Input dimensions: \n",
        "    #   context: Tensor dim [seq_len, batch_size].\n",
        "    #   endings: tuple of Tensors - \n",
        "    #            (dim [end_seq_len*, batch_size or num_endings] - endings, \n",
        "    #             dim [batch_size or num_endings] - batch lengths).\n",
        "    #   Training: num_endings = 1; decoding: batch_size = 1.\n",
        "    def forward(self, context, endings, itos=None):\n",
        "        # context not used.\n",
        "        ends = endings[0]\n",
        "        ends_ls = endings[1]\n",
        "\n",
        "        end_seq_len = ends.size()[0]\n",
        "        end = ends.view(end_seq_len, -1)\n",
        "        end_batch_size = end.size()[1]\n",
        "        maxpool_end = nn.MaxPool1d(end_seq_len)\n",
        "\n",
        "        end_embed = self.embed_seq(end)\n",
        "        end_pooled = maxpool_end(end_embed).view(end_batch_size, self.embedding_dim)\n",
        "        #end_pooled = torch.sum(end_conv, 2)/end_seq_len\n",
        "\n",
        "        final = self.fc(end_pooled).view(-1)\n",
        "        return final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgDnVg1t1i_7"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class SplitCrossEntropyLoss(nn.Module):\n",
        "    r'''SplitCrossEntropyLoss calculates an approximate softmax'''\n",
        "    def __init__(self, hidden_size, splits, verbose=False):\n",
        "        # We assume splits is [0, split1, split2, N] where N >= |V|\n",
        "        # For example, a vocab of 1000 words may have splits [0] + [100, 500] + [inf]\n",
        "        super(SplitCrossEntropyLoss, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.splits = [0] + splits + [100 * 1000000]\n",
        "        self.nsplits = len(self.splits) - 1\n",
        "        self.stats = defaultdict(list)\n",
        "        self.verbose = verbose\n",
        "        # Each of the splits that aren't in the head require a pretend token, we'll call them tombstones\n",
        "        # The probability given to this tombstone is the probability of selecting an item from the represented split\n",
        "        if self.nsplits > 1:\n",
        "            self.tail_vectors = nn.Parameter(torch.zeros(self.nsplits - 1, hidden_size))\n",
        "            self.tail_bias = nn.Parameter(torch.zeros(self.nsplits - 1))\n",
        "\n",
        "    def logprob(self, weight, bias, hiddens, splits=None, softmaxed_head_res=None, verbose=False):\n",
        "        # First we perform the first softmax on the head vocabulary and the tombstones\n",
        "        if softmaxed_head_res is None:\n",
        "            start, end = self.splits[0], self.splits[1]\n",
        "            head_weight = None if end - start == 0 else weight[start:end]\n",
        "            head_bias = None if end - start == 0 else bias[start:end]\n",
        "            # We only add the tombstones if we have more than one split\n",
        "            if self.nsplits > 1:\n",
        "                head_weight = self.tail_vectors if head_weight is None else torch.cat([head_weight, self.tail_vectors])\n",
        "                head_bias = self.tail_bias if head_bias is None else torch.cat([head_bias, self.tail_bias])\n",
        "\n",
        "            # Perform the softmax calculation for the word vectors in the head for all splits\n",
        "            # We need to guard against empty splits as torch.cat does not like random lists\n",
        "            head_res = torch.nn.functional.linear(hiddens, head_weight, bias=head_bias)\n",
        "            softmaxed_head_res = torch.nn.functional.log_softmax(head_res, dim=-1)\n",
        "\n",
        "        if splits is None:\n",
        "            splits = list(range(self.nsplits))\n",
        "\n",
        "        results = []\n",
        "        running_offset = 0\n",
        "        for idx in splits:\n",
        "\n",
        "            # For those targets in the head (idx == 0) we only need to return their loss\n",
        "            if idx == 0:\n",
        "                results.append(softmaxed_head_res[:, :-(self.nsplits - 1)])\n",
        "\n",
        "            # If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)\n",
        "            else:\n",
        "                start, end = self.splits[idx], self.splits[idx + 1]\n",
        "                tail_weight = weight[start:end]\n",
        "                tail_bias = bias[start:end]\n",
        "\n",
        "                # Calculate the softmax for the words in the tombstone\n",
        "                tail_res = torch.nn.functional.linear(hiddens, tail_weight, bias=tail_bias)\n",
        "\n",
        "                # Then we calculate p(tombstone) * p(word in tombstone)\n",
        "                # Adding is equivalent to multiplication in log space\n",
        "                head_entropy = (softmaxed_head_res[:, -idx]).contiguous()\n",
        "                tail_entropy = torch.nn.functional.log_softmax(tail_res, dim=-1)\n",
        "                results.append(head_entropy.view(-1, 1) + tail_entropy)\n",
        "\n",
        "        if len(results) > 1:\n",
        "            return torch.cat(results, dim=1)\n",
        "        return results[0]\n",
        "\n",
        "    def split_on_targets(self, hiddens, targets):\n",
        "        # Split the targets into those in the head and in the tail\n",
        "        split_targets = []\n",
        "        split_hiddens = []\n",
        "\n",
        "        # Determine to which split each element belongs (for each start split value, add 1 if equal or greater)\n",
        "        # This method appears slower at least for WT-103 values for approx softmax\n",
        "        #masks = [(targets >= self.splits[idx]).view(1, -1) for idx in range(1, self.nsplits)]\n",
        "        #mask = torch.sum(torch.cat(masks, dim=0), dim=0)\n",
        "        ###\n",
        "        # This is equally fast for smaller splits as method below but scales linearly\n",
        "        mask = None\n",
        "        for idx in range(1, self.nsplits):\n",
        "            partial_mask = targets >= self.splits[idx]\n",
        "            mask = mask + partial_mask if mask is not None else partial_mask\n",
        "        ###\n",
        "        #masks = torch.stack([targets] * (self.nsplits - 1))\n",
        "        #mask = torch.sum(masks >= self.split_starts, dim=0)\n",
        "        for idx in range(self.nsplits):\n",
        "            # If there are no splits, avoid costly masked select\n",
        "            if self.nsplits == 1:\n",
        "                split_targets, split_hiddens = [targets], [hiddens]\n",
        "                continue\n",
        "            # If all the words are covered by earlier targets, we have empties so later stages don't freak out\n",
        "            if sum(len(t) for t in split_targets) == len(targets):\n",
        "                split_targets.append([])\n",
        "                split_hiddens.append([])\n",
        "                continue\n",
        "            # Are you in our split?\n",
        "            tmp_mask = mask == idx\n",
        "            split_targets.append(torch.masked_select(targets, tmp_mask))\n",
        "            split_hiddens.append(hiddens.masked_select(tmp_mask.unsqueeze(1).expand_as(hiddens)).view(-1, hiddens.size(1)))\n",
        "        return split_targets, split_hiddens\n",
        "\n",
        "    def forward(self, weight, bias, hiddens, targets, verbose=False):\n",
        "        if self.verbose or verbose:\n",
        "            for idx in sorted(self.stats):\n",
        "                print('{}: {}'.format(idx, int(np.mean(self.stats[idx]))), end=', ')\n",
        "            print()\n",
        "\n",
        "        total_loss = None\n",
        "        if len(hiddens.size()) > 2: hiddens = hiddens.view(-1, hiddens.size(2))\n",
        "\n",
        "        split_targets, split_hiddens = self.split_on_targets(hiddens, targets)\n",
        "\n",
        "        # First we perform the first softmax on the head vocabulary and the tombstones\n",
        "        start, end = self.splits[0], self.splits[1]\n",
        "        head_weight = None if end - start == 0 else weight[start:end]\n",
        "        head_bias = None if end - start == 0 else bias[start:end]\n",
        "\n",
        "        # We only add the tombstones if we have more than one split\n",
        "        if self.nsplits > 1:\n",
        "            head_weight = self.tail_vectors if head_weight is None else torch.cat([head_weight, self.tail_vectors])\n",
        "            head_bias = self.tail_bias if head_bias is None else torch.cat([head_bias, self.tail_bias])\n",
        "\n",
        "        # Perform the softmax calculation for the word vectors in the head for all splits\n",
        "        # We need to guard against empty splits as torch.cat does not like random lists\n",
        "        combo = torch.cat([split_hiddens[i] for i in range(self.nsplits) if len(split_hiddens[i])])\n",
        "        ###\n",
        "        all_head_res = torch.nn.functional.linear(combo, head_weight, bias=head_bias)\n",
        "        softmaxed_all_head_res = torch.nn.functional.log_softmax(all_head_res, dim=-1)\n",
        "        if self.verbose or verbose:\n",
        "            self.stats[0].append(combo.size()[0] * head_weight.size()[0])\n",
        "\n",
        "        running_offset = 0\n",
        "        for idx in range(self.nsplits):\n",
        "            # If there are no targets for this split, continue\n",
        "            if len(split_targets[idx]) == 0: continue\n",
        "\n",
        "            # For those targets in the head (idx == 0) we only need to return their loss\n",
        "            if idx == 0:\n",
        "                softmaxed_head_res = softmaxed_all_head_res[running_offset:running_offset + len(split_hiddens[idx])]\n",
        "                entropy = -torch.gather(softmaxed_head_res, dim=1, index=split_targets[idx].view(-1, 1))\n",
        "            # If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)\n",
        "            else:\n",
        "                softmaxed_head_res = softmaxed_all_head_res[running_offset:running_offset + len(split_hiddens[idx])]\n",
        "\n",
        "                if self.verbose or verbose:\n",
        "                    start, end = self.splits[idx], self.splits[idx + 1]\n",
        "                    tail_weight = weight[start:end]\n",
        "                    self.stats[idx].append(split_hiddens[idx].size()[0] * tail_weight.size()[0])\n",
        "\n",
        "                # Calculate the softmax for the words in the tombstone\n",
        "                tail_res = self.logprob(weight, bias, split_hiddens[idx], splits=[idx], softmaxed_head_res=softmaxed_head_res)\n",
        "\n",
        "                # Then we calculate p(tombstone) * p(word in tombstone)\n",
        "                # Adding is equivalent to multiplication in log space\n",
        "                head_entropy = softmaxed_head_res[:, -idx]\n",
        "                # All indices are shifted - if the first split handles [0,...,499] then the 500th in the second split will be 0 indexed\n",
        "                indices = (split_targets[idx] - self.splits[idx]).view(-1, 1)\n",
        "                # Warning: if you don't squeeze, you get an N x 1 return, which acts oddly with broadcasting\n",
        "                tail_entropy = torch.gather(torch.nn.functional.log_softmax(tail_res, dim=-1), dim=1, index=indices).squeeze()\n",
        "                entropy = -(head_entropy + tail_entropy)\n",
        "            ###\n",
        "            running_offset += len(split_hiddens[idx])\n",
        "            total_loss = entropy.float().sum() if total_loss is None else total_loss + entropy.float().sum()\n",
        "\n",
        "        return (total_loss / len(targets)).type_as(weight)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    np.random.seed(42)\n",
        "    torch.manual_seed(42)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(42)\n",
        "\n",
        "    V = 8\n",
        "    H = 10\n",
        "    N = 100\n",
        "    E = 10\n",
        "\n",
        "    embed = torch.nn.Embedding(V, H)\n",
        "    crit = SplitCrossEntropyLoss(hidden_size=H, splits=[V // 2])\n",
        "    bias = torch.nn.Parameter(torch.ones(V))\n",
        "    optimizer = torch.optim.SGD(list(embed.parameters()) + list(crit.parameters()), lr=1)\n",
        "\n",
        "    for _ in range(E):\n",
        "        prev = torch.autograd.Variable((torch.rand(N, 1) * 0.999 * V).int().long())\n",
        "        x = torch.autograd.Variable((torch.rand(N, 1) * 0.999 * V).int().long())\n",
        "        y = embed(prev).squeeze()\n",
        "        c = crit(embed.weight, bias, y, x.view(N))\n",
        "        print('Crit', c.exp().data[0])\n",
        "\n",
        "        logprobs = crit.logprob(embed.weight, bias, y[:2]).exp()\n",
        "        print(logprobs)\n",
        "        print(logprobs.sum(dim=1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        c.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTxoFdWMze5B"
      },
      "source": [
        "Testing based on the pre-trained "
      ]
    }
  ]
}